{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDdPniKEu7ia"
   },
   "source": [
    "# BAN200 Week 01 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ebn9PTsc6C3g"
   },
   "source": [
    "To complete the homework you will need to modify this template by adding Python code and/or text.\n",
    "\n",
    "Before starting the homework, make sure to save a copy of this template to your personal Google Drive. If you haven't saved your own copy, any changes you make will be lost when you close your browser window.\n",
    "\n",
    "To submit your homework: go to \"File\" in the Colab menu bar > select \"Download\" > select \"Download .ipynb\". This will download a \".ipynb\" file to your computer. You must submit this file.\n",
    "\n",
    "The homework is to be completed in groups. It is due at the start of next class.\n",
    "\n",
    "Homework is graded on the following scale:\n",
    "\n",
    "* *100%* -- The assignment was submitted on time, any code runs without errors, and every question is answered correctly.\n",
    "\n",
    "* *80%* -- The assignment was submitted on time, any code runs without errors, and every question is answered. Some questions may be incorrect, but the submission demonstrates an average level of effort and average level of understanding of the material.\n",
    "\n",
    "* *60%* -- The submission demonstrates a below-average level of effort and below-average level of understanding of the material. This is the highest grade that should be given to submissions that are submitted late, have code that throws uncaught errors, or leave some questions unanswered.\n",
    "\n",
    "* *0%* -- No assignment was submitted, or the submission demonstrates little-to-no effort and little-to-no understanding of the material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYcvY8gEwszK"
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXLVXlwxvQAu"
   },
   "source": [
    "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
    "```\n",
    "I love McDonalds!\n",
    "```\n",
    "Your list should be stored in a variable `tweet_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MhuYLJ9ru3UY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'McDonalds!']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your answer here\n",
    "text0 = \"I love McDonalds!\"\n",
    "tweet_0 = text0.split()\n",
    "tweet_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs8s0KVfwvPQ"
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sibMSRSkwvZW"
   },
   "source": [
    "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
    "```\n",
    "McDonalds: you are so good ...\n",
    "```\n",
    "Your list should be stored in a variable `tweet_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DPR15yQRxNm7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['McDonalds:', 'you', 'are', 'so', 'good', '...']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your answer here\n",
    "text1 = \"McDonalds: you are so good ...\"\n",
    "tweet_1 = text1.split()\n",
    "tweet_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuhYPiUjyZqS"
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nh2axebEyZqU"
   },
   "source": [
    "Represent this tweet as a Python list of word tokens, ignoring any non-alphanumeric characters:\n",
    "```\n",
    "This McDonalds hamburger, it is gross\n",
    "```\n",
    "Your list should be stored in a variable `tweet_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RAGTbXTPyZqU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'McDonalds', 'hamburger,', 'it', 'is', 'gross']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your answer here\n",
    "text2 = \"This McDonalds hamburger, it is gross\"\n",
    "tweet_2 = text2.split()\n",
    "tweet_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJXKnNWG_Zdr"
   },
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nR2dofHV_dge"
   },
   "source": [
    "Represent this lexicon as a Python dictionary called `lexicon`:\n",
    "\n",
    "```\n",
    "+2.1  love\n",
    "+1.8  good\n",
    "-1.5  gross\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DUFEM1dpA6VQ"
   },
   "outputs": [],
   "source": [
    "# put your answer here\n",
    "lexicon = {\n",
    "    \"love\": 2.1,\n",
    "    \"good\": 1.8,\n",
    "    \"gross\": -1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozA3GUqDzXpy"
   },
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzJ1Ht1-zZw0"
   },
   "source": [
    "Use a for loop to iterate over all of the tokens in `tweet_2` and make them lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4prOUtnDzaOE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "mcdonalds\n",
      "hamburger,\n",
      "it\n",
      "is\n",
      "gross\n"
     ]
    }
   ],
   "source": [
    "# put your answer here\n",
    "for term in tweet_2:\n",
    "    print(term.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwM5Sph5BbYe"
   },
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtSJ-32yBbYf"
   },
   "source": [
    "Use a for loop to calculate a sentiment score for `tweet_2` using `lexicon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ykReYpiwBbYf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your answer here\n",
    "def calculate_sentiment_score(tokens, lexicon):\n",
    "    score = 0\n",
    "    for token in tokens:\n",
    "        if token in lexicon:\n",
    "            score = score+ lexicon[token]\n",
    "    return score\n",
    "\n",
    "sentiment_score = calculate_sentiment_score(tweet_2, lexicon)\n",
    "sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBZ1DuR0B0LN"
   },
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eak51Y5gB0LO"
   },
   "source": [
    "Create a function that takes two parameters -- a list of tokens and a lexicon -- and returns a sentiment score. Test-out your function with `tweet_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CD_9162rB0LP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your answer here\n",
    "def calculate_sentiment_score(tokens, lexicon):\n",
    "    score = 0\n",
    "    for token in tokens:\n",
    "        if token in lexicon:\n",
    "            score = score+ lexicon[token]\n",
    "    return score\n",
    "\n",
    "sentiment_score = calculate_sentiment_score(tweet_2, lexicon)\n",
    "sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzp8AShL02T7"
   },
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu1GJe7Z04RO"
   },
   "source": [
    "Create a function that takes a list of tokens as a paramater and makes them lower case. You can repurpose your code from Question 5. Test-out your function with `tweet_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I2j6XV3003eK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your answer here\n",
    "sentiment_score = calculate_sentiment_score(tweet_1, lexicon)\n",
    "sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbyMF6StxQm-"
   },
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brjrHomcxR3u"
   },
   "source": [
    "Create a new variable `corpus` that stores the three earlier tweets in a \"list of lists\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p0D9k0XdzRUR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'love', 'McDonalds!'], ['McDonalds:', 'you', 'are', 'so', 'good', '...'], ['This', 'McDonalds', 'hamburger,', 'it', 'is', 'gross']]\n"
     ]
    }
   ],
   "source": [
    "# put your answer here\n",
    "tweet_0 = \"I love McDonalds!\"\n",
    "tweet_1 = \"McDonalds: you are so good ...\"\n",
    "tweet_2 = \"This McDonalds hamburger, it is gross\"\n",
    "\n",
    "tokens_0 = tweet_0.split()\n",
    "tokens_1 = tweet_1.split()\n",
    "tokens_2 = tweet_2.split()\n",
    "\n",
    "corpus = [tokens_0, tokens_1, tokens_2]\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-6RVuSm-knj"
   },
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obzpKZnn-lv3"
   },
   "source": [
    "Use a for loop to iterate over all of the tweets in `corpus` and use your function from Question 8 to make all of the tokens lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nVPLGpPo-00p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'love', 'mcdonalds!'], ['mcdonalds:', 'you', 'are', 'so', 'good', '...'], ['this', 'mcdonalds', 'hamburger,', 'it', 'is', 'gross']]\n"
     ]
    }
   ],
   "source": [
    "# put your answer here\n",
    "def convert_tokens_to_lowercase(tokens):\n",
    "    lowercase_tokens = [token.lower() for token in tokens]\n",
    "    return lowercase_tokens\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = convert_tokens_to_lowercase(corpus[i])\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zZUcayuCh3b"
   },
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_1GxD65CjRP"
   },
   "source": [
    "Use a for loop and your function from Question 7 to print-out scores for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5O9AvoNSCtdF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score of tweet 0 is 2.1\n",
      "Sentiment score of tweet 1 is 1.8\n",
      "Sentiment score of tweet 2 is -1.5\n"
     ]
    }
   ],
   "source": [
    "# put your answer here\n",
    "\n",
    "def calculate_sentiment_score(tokens, lexicon):\n",
    "  score=0\n",
    "  for token in tokens:\n",
    "    if token in lexicon:\n",
    "      score = score + lexicon[token]\n",
    "      return score\n",
    "\n",
    "\n",
    "\n",
    "tweet_0 = \"I love McDonalds!\"\n",
    "tweet_1 = \"McDonalds: you are so good ...\"\n",
    "tweet_2 = \"This McDonalds hamburger, it is gross\"\n",
    "\n",
    "tweets=[tweet_0,tweet_1,tweet_2]\n",
    "\n",
    "for index,i in enumerate(tweets):\n",
    "  tokens=i.split()\n",
    "  sentiment_score=calculate_sentiment_score(tokens,lexicon)\n",
    "  print(f\"Sentiment score of tweet {index} is\", sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glJVQiVyDjbR"
   },
   "source": [
    "# Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-5hmNnhDlez"
   },
   "source": [
    "Use your function from Question 7 to score the tweet `McDonalds is not great`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ekJKKy3nDkrD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment score: None\n"
     ]
    }
   ],
   "source": [
    "# put your answer here\n",
    "review=\"McDonalds is not great\"\n",
    "review_split=review.split()\n",
    "\n",
    "lexicon = {\n",
    "    \"love\": 2.1,\n",
    "    \"good\": 1.8,\n",
    "    \"gross\": -1.5,\n",
    "}\n",
    "\n",
    "def calculate_sentiment_score(tokens, lexicon):\n",
    "  score=0\n",
    "  for token in tokens:\n",
    "    if token in lexicon:\n",
    "      score = score + lexicon[token]\n",
    "      return score\n",
    "sentiment_score=calculate_sentiment_score(review_split,lexicon)\n",
    "print(\"Sentiment score:\", sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RYUnxt1DuBZ"
   },
   "source": [
    "# Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wg8XyVSLEA28"
   },
   "source": [
    "In one or two sentences, explain the pros and cons of our sentiment model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bu-g5h7EO8I"
   },
   "source": [
    "*put your answer here*\n",
    "Pros of our sentiment model\n",
    " - It will be useful for small amount of data and small tweets.\n",
    " - Its easy to classify the sentiment score on the basis of lexicon\n",
    " \n",
    "Cons of our sentiment model\n",
    " - It will be difficult to identify the score for confusing sentences like \"McDonalds is not great.\"\n",
    " - It will be impossible to get correct score for longer tweets. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7pLvPjM9eNn6wZjcAwHRh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
